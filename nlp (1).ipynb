{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "import os\n",
    "from jiwer import wer\n",
    "import datetime\n",
    "import pyttsx3 \n",
    "import webbrowser\n",
    "import wikipedia\n",
    "from jaccard_index.jaccard import jaccard_index\n",
    "#import pyttsx3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()  \n",
    "engine.setProperty('rate', 125) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myCommand():\n",
    "    r = sr.Recognizer()\n",
    "    \n",
    "    with sr.Microphone() as source:\n",
    "        r.energy_threshold=9000\n",
    "        r.adjust_for_ambient_noise(source,1.2)\n",
    "        #r.pause_threshold=1\n",
    "        audio = r.listen(source)\n",
    "        \n",
    "        #command=\"\"\n",
    "    try:\n",
    "        \n",
    "        command = r.recognize_google(audio)\n",
    "        \n",
    "        print('You said: ' + command + '\\n')\n",
    "        #speak(command)\n",
    "    #loop back to continue to listen for commands if unrecognizable speech is received\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "       \n",
    "    return command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myhindiCommand():\n",
    "    r1 = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        Haudio = r1.listen(source)\n",
    "        Hcommand=\"\"\n",
    "    try:\n",
    "        Hcommand = r1.recognize_google(Haudio,language='hi-In')\n",
    "        print('You said: ' + Hcommand + '\\n')\n",
    "        #speak(command)\n",
    "    #loop back to continue to listen for commands if unrecognizable speech is received\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "       \n",
    "    return Hcommand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myhindiCommand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(audio):\n",
    "    engine.say(audio)  \n",
    "    engine.runAndWait()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wishme():\n",
    "    hour=int(datetime.datetime.now().hour)\n",
    "    if hour >0 and hour<12:\n",
    "        speak(\"Good morning\")\n",
    "    elif hour>=12 and hour<16:\n",
    "        speak(\"Good afternoon\")\n",
    "    elif hour >=16 and hour<19:\n",
    "        speak(\"good evening\")\n",
    "    else:\n",
    "        speak(\"good night\")\n",
    "    speak(\"I am Jarvis..How can I help you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    wishme()\n",
    "    while True:\n",
    "        query=myCommand().lower()\n",
    "        if 'stop' in query or 'bye' in query:\n",
    "            speak('have a good day sir')\n",
    "            break\n",
    "        elif 'tell me about' in query:\n",
    "            speak('Searching wikipedia result....')\n",
    "            query=query.replace('tell me about','')\n",
    "            print(query)\n",
    "            result=wikipedia.summary(query,sentences=2)\n",
    "            speak(\"According wikipedia\")\n",
    "            speak(result)\n",
    "        elif 'open youtube' in query:\n",
    "            webbrowser.open('youtube.com')\n",
    "\n",
    "        elif 'open google' in query:\n",
    "            webbrowser.open('google.com')\n",
    "\n",
    "        \n",
    "\n",
    "        elif 'play music' in query:\n",
    "            music_dir=\"F:\\\\songs\"\n",
    "            songs=os.listdir(music_dir)\n",
    "            num=random.randint(0,len(music_dir))\n",
    "            os.startfile(os.path.join(music_dir,songs[num]))\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"hypothesis.txt\", 'r') as file:\n",
    "    data = file.read().replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data. The result is a computer capable of \"understanding\" the contents of documents, including the contextual nuances of the language within them. The technology can then accurately extract information and insights contained in the documents as well as categorize and organize the documents themselves.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data=data.lower()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* recording\n",
      "* done recording\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 40\n",
    "WAVE_OUTPUT_FILENAME = \"output.wav\"\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK)\n",
    "\n",
    "print(\"* recording\")\n",
    "\n",
    "frames = []\n",
    "\n",
    "for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "    data = stream.read(CHUNK)\n",
    "    frames.append(data)\n",
    "\n",
    "print(\"* done recording\")\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "p.terminate()\n",
    "\n",
    "wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "wf.setnchannels(CHANNELS)\n",
    "wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "wf.setframerate(RATE)\n",
    "wf.writeframes(b''.join(frames))\n",
    "wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r3=sr.Recognizer()\n",
    "with sr.Microphone() as source:\n",
    "    audio=r3.listen(source)\n",
    "    \n",
    "    with open('recognized.wav','wb') as f:\n",
    "        f.write(audio.get_wav_data())\n",
    "        \n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognizefile():\n",
    "    r4=sr.Recognizer()\n",
    "    with sr.AudioFile('output.wav') as source:\n",
    "        audio=r4.listen(source)\n",
    "        text=''\n",
    "    try:\n",
    "        text=r4.recognize_google(audio)\n",
    "\n",
    "        print(text)\n",
    "    except:\n",
    "        print('j')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing is a subfield of linguistic computer science and artificial intelligence concerned with the interactions between computers and human language in particular how to program computers to process and analysing large amount of natural language data the result is a computer capable of understanding the context of documents including the contacts velocities of language within them the technology can then accurately extract information and insight contained in document as well as categorise and organise the document themselves\n"
     ]
    }
   ],
   "source": [
    "mywords=recognizefile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "jaccaurd_score=jaccard_index(data,mywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3048780487804878"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer(data,mywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8726114649681529"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccaurd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural Language Processing is a subfield of linguistic computer science and artificial intelligence concerned with interactions between computers and human language in particular how to program computers to process and analyse large amount of natural language data the result is a computer capable of understanding the context of documents including the context losses of language between them and Technology can then accurately access information and in self contained in documents as well as categorised and organised the documents themselves\n"
     ]
    }
   ],
   "source": [
    "wordswithnoise=recognizefile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordswithnoise=wordswithnoise.lower()\n",
    "\n",
    "jaccaurd_score=jaccard_index(data,wordswithnoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34146341463414637"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wer(data,wordswithnoise)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83125"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccaurd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REF: this was reference       \n",
      "HYP: This is  hypothesis file \n",
      "EVA: S    S   S          I    \n",
      "WER: 133.33%\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy\n",
    "\n",
    "def editDistance(r, h):\n",
    "    '''\n",
    "    This function is to calculate the edit distance of reference sentence and the hypothesis sentence.\n",
    "    Main algorithm used is dynamic programming.\n",
    "    Attributes: \n",
    "        r -> the list of words produced by splitting reference sentence.\n",
    "        h -> the list of words produced by splitting hypothesis sentence.\n",
    "    '''\n",
    "    d = numpy.zeros((len(r)+1)*(len(h)+1), dtype=numpy.uint8).reshape((len(r)+1, len(h)+1))\n",
    "    for i in range(len(r)+1):\n",
    "        d[i][0] = i\n",
    "    for j in range(len(h)+1):\n",
    "        d[0][j] = j\n",
    "    for i in range(1, len(r)+1):\n",
    "        for j in range(1, len(h)+1):\n",
    "            if r[i-1] == h[j-1]:\n",
    "                d[i][j] = d[i-1][j-1]\n",
    "            else:\n",
    "                substitute = d[i-1][j-1] + 1\n",
    "                insert = d[i][j-1] + 1\n",
    "                delete = d[i-1][j] + 1\n",
    "                d[i][j] = min(substitute, insert, delete)\n",
    "    return d\n",
    "\n",
    "def getStepList(r, h, d):\n",
    "    '''\n",
    "    This function is to get the list of steps in the process of dynamic programming.\n",
    "    Attributes: \n",
    "        r -> the list of words produced by splitting reference sentence.\n",
    "        h -> the list of words produced by splitting hypothesis sentence.\n",
    "        d -> the matrix built when calulating the editting distance of h and r.\n",
    "    '''\n",
    "    x = len(r)\n",
    "    y = len(h)\n",
    "    list = []\n",
    "    while True:\n",
    "        if x == 0 and y == 0: \n",
    "            break\n",
    "        elif x >= 1 and y >= 1 and d[x][y] == d[x-1][y-1] and r[x-1] == h[y-1]: \n",
    "            list.append(\"e\")\n",
    "            x = x - 1\n",
    "            y = y - 1\n",
    "        elif y >= 1 and d[x][y] == d[x][y-1]+1:\n",
    "            list.append(\"i\")\n",
    "            x = x\n",
    "            y = y - 1\n",
    "        elif x >= 1 and y >= 1 and d[x][y] == d[x-1][y-1]+1:\n",
    "            list.append(\"s\")\n",
    "            x = x - 1\n",
    "            y = y - 1\n",
    "        else:\n",
    "            list.append(\"d\")\n",
    "            x = x - 1\n",
    "            y = y\n",
    "    return list[::-1]\n",
    "\n",
    "def alignedPrint(list, r, h, result):\n",
    "    '''\n",
    "    This funcition is to print the result of comparing reference and hypothesis sentences in an aligned way.\n",
    "    \n",
    "    Attributes:\n",
    "        list   -> the list of steps.\n",
    "        r      -> the list of words produced by splitting reference sentence.\n",
    "        h      -> the list of words produced by splitting hypothesis sentence.\n",
    "        result -> the rate calculated based on edit distance.\n",
    "    '''\n",
    "    print(\"REF:\", end=\" \")\n",
    "    for i in range(len(list)):\n",
    "        if list[i] == \"i\":\n",
    "            count = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"d\":\n",
    "                    count += 1\n",
    "            index = i - count\n",
    "            print(\" \"*(len(h[index])), end=\" \")\n",
    "        elif list[i] == \"s\":\n",
    "            count1 = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"i\":\n",
    "                    count1 += 1\n",
    "            index1 = i - count1\n",
    "            count2 = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"d\":\n",
    "                    count2 += 1\n",
    "            index2 = i - count2\n",
    "            if len(r[index1]) < len(h[index2]):\n",
    "                print(r[index1] + \" \" * (len(h[index2])-len(r[index1])), end=\" \")\n",
    "            else:\n",
    "                print(r[index1], end=\" \"),\n",
    "        else:\n",
    "            count = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"i\":\n",
    "                    count += 1\n",
    "            index = i - count\n",
    "            print(r[index], end=\" \"),\n",
    "    print(\"\\nHYP:\", end=\" \")\n",
    "    for i in range(len(list)):\n",
    "        if list[i] == \"d\":\n",
    "            count = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"i\":\n",
    "                    count += 1\n",
    "            index = i - count\n",
    "            print(\" \" * (len(r[index])), end=\" \")\n",
    "        elif list[i] == \"s\":\n",
    "            count1 = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"i\":\n",
    "                    count1 += 1\n",
    "            index1 = i - count1\n",
    "            count2 = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"d\":\n",
    "                    count2 += 1\n",
    "            index2 = i - count2\n",
    "            if len(r[index1]) > len(h[index2]):\n",
    "                print(h[index2] + \" \" * (len(r[index1])-len(h[index2])), end=\" \")\n",
    "            else:\n",
    "                print(h[index2], end=\" \")\n",
    "        else:\n",
    "            count = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"d\":\n",
    "                    count += 1\n",
    "            index = i - count\n",
    "            print(h[index], end=\" \")\n",
    "    print(\"\\nEVA:\", end=\" \")\n",
    "    for i in range(len(list)):\n",
    "        if list[i] == \"d\":\n",
    "            count = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"i\":\n",
    "                    count += 1\n",
    "            index = i - count\n",
    "            print(\"D\" + \" \" * (len(r[index])-1), end=\" \")\n",
    "        elif list[i] == \"i\":\n",
    "            count = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"d\":\n",
    "                    count += 1\n",
    "            index = i - count\n",
    "            print(\"I\" + \" \" * (len(h[index])-1), end=\" \")\n",
    "        elif list[i] == \"s\":\n",
    "            count1 = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"i\":\n",
    "                    count1 += 1\n",
    "            index1 = i - count1\n",
    "            count2 = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"d\":\n",
    "                    count2 += 1\n",
    "            index2 = i - count2\n",
    "            if len(r[index1]) > len(h[index2]):\n",
    "                print(\"S\" + \" \" * (len(r[index1])-1), end=\" \")\n",
    "            else:\n",
    "                print(\"S\" + \" \" * (len(h[index2])-1), end=\" \")\n",
    "        else:\n",
    "            count = 0\n",
    "            for j in range(i):\n",
    "                if list[j] == \"i\":\n",
    "                    count += 1\n",
    "            index = i - count\n",
    "            print(\" \" * (len(r[index])), end=\" \")\n",
    "    print(\"\\nWER: \" + result)\n",
    "\n",
    "def werr(r, h):\n",
    "    \"\"\"\n",
    "    This is a function that calculate the word error rate in ASR.\n",
    "    You can use it like this: wer(\"what is it\".split(), \"what is\".split()) \n",
    "    \"\"\"\n",
    "    # build the matrix\n",
    "    d = editDistance(r, h)\n",
    "\n",
    "    # find out the manipulation steps\n",
    "    list = getStepList(r, h, d)\n",
    "\n",
    "    # print the result in aligned way\n",
    "    result = float(d[len(r)][len(h)]) / len(r) * 100\n",
    "    result = str(\"%.2f\" % result) + \"%\"\n",
    "    alignedPrint(list, r, h, result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename1='reference.txt'\n",
    "    \n",
    "    filename2='hypothesis.txt'\n",
    "    with open(filename1, 'r', encoding=\"utf8\") as ref:\n",
    "        r = ref.read().split()\n",
    "    with open(filename2, 'r', encoding=\"utf8\") as hyp:\n",
    "        h = hyp.read().split()\n",
    "    werr(r,h)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=recognizefile()\n",
    "text=text.lower()\n",
    "error=wer(data,text)\n",
    "error=error*100\n",
    "jaccaurd_score=jaccard_index(data,text)\n",
    "print(\"Word error rate=\",error)\n",
    "print(\"Jaccauard score is=\",jaccaurd_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
